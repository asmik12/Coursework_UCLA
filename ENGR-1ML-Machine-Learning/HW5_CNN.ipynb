{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfT61medTBY6"
      },
      "source": [
        "üìù Hello, this is the Week 6 in-lecture notebook to complete during class.\n",
        "\n",
        "In Lecture 7 we will finish our discussion of fully connected nueral networks üß† and begin discussing convolutional neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NXxusJ3usBR",
        "outputId": "0faa14ea-7d25-466a-925b-eda9aae6bf04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (2025.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asmi_\\asmi's documents\\academics\\2022-26_ucla\\coursework_ucla\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JSocVUB5H3nw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1bPMoyyTRSB"
      },
      "source": [
        "For your final homework (the one assigned last week) you are using PyTorch to do a linear regression assignment, similar to the assignments you had in previous homeworks. This notebook is here to help build up some of the pieces you will use going forward when making neural networks.\n",
        "\n",
        "Let's imagine we are building a classifier for images. These images will be given to us as grayscale 3x3 images. (These would obviously be VERY simple images, this is just for tutorial reasons.) These images can either be bears üêª, dogs üêï, cats üêà, or fish üêü.\n",
        "\n",
        "First a few questions to think about:\n",
        "1. How many inputs does our neural network have?\n",
        "2. How should we change our input to make it easier to feed to the neural network?\n",
        "3. How many outputs does our neural network have?\n",
        "4. If our neural network does not use hidden layers, what would the dimensions of the array that represent our transformation from input to output be?\n",
        "5. What does this say about the dimensions of the arrays that make up all of our stages?\n",
        "\n",
        "üì∞ Task 1: Convert the 3x3 tensor into a 1x9 tensor which will be a better input for our neural network. First do this with the individual tensor (in1), then try to do it with the list of tensors (our \"training data\"). Then append the flattened in1 to the flattened training data (making it the 100th piece of data).\n",
        "\n",
        "Hint: consider using one of the following:\n",
        "* torch.flatten\n",
        "* torch.reshape\n",
        "* torch.cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eR5x6DE7H5vr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 9])\n",
            "torch.Size([99, 9])\n",
            "torch.Size([100, 9])\n"
          ]
        }
      ],
      "source": [
        "#3x3 tensor\n",
        "\n",
        "np.random.seed(0)\n",
        "in1_numpy = np.random.randint(256, size=(3,3))\n",
        "in1 = torch.tensor(in1_numpy, dtype=torch.float)\n",
        "\n",
        "in99_numpy = np.random.randint(256, size=(99, 3, 3))\n",
        "in99 = torch.tensor(in99_numpy, dtype=torch.float)\n",
        "\n",
        "picture_labels_numpy = np.random.randint(4, size=(100))\n",
        "picture_labels = torch.tensor(picture_labels_numpy, dtype=torch.float)\n",
        "\n",
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "# Task 1: Flatten in1 to be a (1x9) tensor, then flatten training_data to a (99x9) tensor, then concatenate both into a (100x9) tensor\n",
        "in1 = in1.reshape(1,9)\n",
        "in99 = in99.reshape(99,9)\n",
        "print(in1.shape)\n",
        "print(in99.shape)\n",
        "final = torch.cat((in1, in99))\n",
        "print(final.shape)\n",
        "\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRNgPNUjd4W7"
      },
      "source": [
        "üöÜ Task 2: Make a simple neural network with one hidden layer for your data. The hidden layer should have 5 neurons on it. You can store your weights in two matrices, and initialize them to 1s or random numbers. Convert your input data to the hidden layer and then that to your output data by multiplying your input by the weight matrices.\n",
        "\n",
        "Things to consider:\n",
        "\n",
        "1. Why do we use matrices to store our weights?\n",
        "\n",
        "2. What will the dimensions of our matrices be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Q7k3ag1dxRP"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "\n",
        "\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5pxir5hdGK"
      },
      "source": [
        "Your output should now be a 100 x 4 matrix of numbers, each of which are unbounded. We would prefer to have each row's values sum to 1, so that the four numbers represent the probability that the image is a bear, dog, cat, or fish, respectively.\n",
        "\n",
        "üßÆ Task 3: Use the softmax function to convert our outputs into probabilities\n",
        "\n",
        "Hint: Look up the torch.nn.functional.log_softmax function! The dim parameter allows us to specify which dimension we want to apply our function along.\n",
        "\n",
        "For example, if we set dim=0, softmax will be applied along the column and each column will sum to 1. Conversely, if we set dim=0, softmax will be applied along the row and each row will sum to 1. Think about which one we want and set dim accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k9ejynAQj5JT"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqj2FomSj8HO"
      },
      "source": [
        "Now we come across a common, but ultimately easy-to-solve problem in neural networks: how we should represent the output. Currently our output is a 100x4 matrix, but picture_labels (the correct output) is a 100x1 matrix.\n",
        "\n",
        "We can convert each row in picture_labels to three zeros and a single one value (1x4) to match our netural network's output. This is called a one-hot encoding. As of now, our actual picture label is only a single value for each image (thus a tensor of 100 values for the 100 images). This is called an integer encoding. Let's convert picture_labels to a one hot encoding so that we can compare it with our neural network's output.\n",
        "\n",
        "Example of conversion from integer to one-hot encoding: \\\n",
        "[0] -> [1 0 0 0] \\\n",
        "[1] -> [0 1 0 0] \\\n",
        "[2] -> [0 0 1 0] \\\n",
        "[3] -> [0 0 0 1]\n",
        "\n",
        "üì≠ Task 4: Use a pytorch function (or make your own) to convert the picture_labels matrix to one hot encoding. Then compute the log-loss of your estimated output and the actual output.\n",
        "\n",
        "Hint: the following may be helpful:\n",
        "*   torch.nn.functional.one_hot\n",
        "*   torch.nn.NLLLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DhucYDLKj5-J"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEuH44pEq7gJ"
      },
      "source": [
        "Now that you have seen how a fully connected neural network works we are going to convert everything into PyTorch. When building actual neural networks in PyTorch we are going to use a class to represent the network. We will train an instance of this class for our model.\n",
        "\n",
        "üîÉ Task 5: Create a class that will represent your neural network structure. You may add any layers you want to this, but keep in mind that between linear layers you are going to want a ReLU. Create the \\_\\_init__() and forward() methods for the class.\n",
        "\n",
        "Hint: the following may be helpful:\n",
        "* https://pytorch.org/docs/stable/generated/torch.nn.Module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fdm5UTzAsXuj"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 10 (1148585271.py, line 13)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    model = NeuralNetwork()\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 10\n"
          ]
        }
      ],
      "source": [
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "\n",
        "model = NeuralNetwork()\n",
        "s\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cQIXBT5zS0p"
      },
      "source": [
        "‚õ≥ Task 6: Use the following training loop to train your model. Don't worry about splitting this model into training and testing data, these are just random values so they should not actually train to anything relevant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-CS9MVbzc_C"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "## YOUR CODE STARTS HERE\n",
        "########################\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "momentum = 1\n",
        "num_epochs_to_print = 1\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "for i in range(num_epochs):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  outputs = model(training_data_flattened)\n",
        "  loss = criterion(outputs, one_hot_picture_labels.float())\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if i % num_epochs_to_print == 0:\n",
        "    print(loss.item())\n",
        "\n",
        "########################\n",
        "## YOUR CODE ENDS HERE\n",
        "########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQWKTTk0lk-"
      },
      "source": [
        "‚è≠ Task 7: (Optional) Add some convolutional neural network layers that we learned in class today to your model and try retraining. Think about the dimensions and what dimensions should be correct (consider printing shapes of the data at various stages)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "bsiakNQNmz6G",
        "outputId": "fae590f7-cb80-45e1-a992-49abde150c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 1]\n",
            " [1 0 0]\n",
            " [1 0 0]]\n",
            "[[3. 1. 1. 0. 0. 0. 1.]\n",
            " [4. 1. 1. 1. 0. 0. 1.]\n",
            " [4. 1. 1. 1. 1. 0. 1.]\n",
            " [3. 1. 1. 1. 1. 1. 1.]\n",
            " [3. 0. 1. 1. 1. 1. 2.]\n",
            " [3. 0. 0. 1. 1. 1. 2.]\n",
            " [3. 0. 0. 0. 1. 1. 2.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def conv(kern, img):\n",
        "  out = np.zeros((7, 7))\n",
        "  for i in range(7):\n",
        "    for j in range(7):\n",
        "      out[i][j] = sum(sum(img[i:i+3, j:j+3] * kern))\n",
        "  return out\n",
        "\n",
        "kernel_temp = [[1,1,1],[1,0,0],[1,0,0]]\n",
        "kernel = np.array(kernel_temp)\n",
        "\n",
        "imageX = np.zeros((9, 9))\n",
        "imageN = np.zeros((9, 9))\n",
        "imageZ = np.zeros((9, 9))\n",
        "imageO = np.zeros((9, 9))\n",
        "for i in range(9):\n",
        "  for j in range(9):\n",
        "    if i == j or i == 8 - j:\n",
        "      imageX[i][j] = 1.0\n",
        "    if i == j or j == 0 or j == 8:\n",
        "      imageN[i][j] = 1.0\n",
        "    if i == 8 - j or i == 0 or i == 8:\n",
        "      imageZ[i][j] = 1.0\n",
        "    if i == 1 or i == 7 or j == 1 or j == 7:\n",
        "      if not (i == 0 or j == 0 or i == 8 or j == 8):\n",
        "        imageO[i][j] = 1.0\n",
        "\n",
        "image = imageN\n",
        "\n",
        "out = conv(kernel, image)\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(kernel)\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(image)\n",
        "plt.colorbar()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(out)\n",
        "plt.colorbar()\n",
        "\n",
        "print(kernel)\n",
        "print(out)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
